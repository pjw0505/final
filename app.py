# =======================================================
# app.py: ê³ ì „ ì˜ˆìˆ  ê¸°ë¡ ë° ë©¸ì‹¤ìœ ì‚° ë°œêµ´ ì—ì´ì „íŠ¸
# =======================================================

import streamlit as st
from openai import OpenAI
import json
import os
import time # ì‹œë®¬ë ˆì´ì…˜ ì§€ì—°ìš©

# -------------------------------------------------------
# 1. í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í•¨ìˆ˜ (st.secrets ì‚¬ìš©)
# -------------------------------------------------------

@st.cache_resource
def get_openai_client():
    """Streamlit Secretsì—ì„œ API í‚¤ë¥¼ ì½ì–´ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    
    # st.secrets ê°ì²´ì—ì„œ API í‚¤ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    try:
        # í‚¤ë¥¼ ê°€ì ¸ì™€ì„œ ì–‘ìª½ ê³µë°±ì´ë‚˜ ì¤„ë°”ê¿ˆ ë¬¸ìë¥¼ í™•ì‹¤íˆ ì œê±°í•©ë‹ˆë‹¤.
        # [secrets] ì„¹ì…˜ ë‚´ OPENAI_API_KEY í•­ëª©ì— ì ‘ê·¼í•©ë‹ˆë‹¤.
        api_key = st.secrets["secrets"]["OPENAI_API_KEY"].strip()
    except KeyError:
        # Secrets ì„¤ì •ì´ ëˆ„ë½ëœ ê²½ìš°
        st.error("ì˜¤ë¥˜: Streamlit Secretsì— [secrets] ì„¹ì…˜ ë˜ëŠ” OPENAI_API_KEYê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.stop()
        
    # í‚¤ ê°’ì´ ìœ íš¨í•œì§€ ìµœì¢… í™•ì¸
    if not api_key or not api_key.startswith("sk-"):
        st.error("ì˜¤ë¥˜: API í‚¤ (OPENAI_API_KEY)ì˜ ê°’ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
        
    return OpenAI(api_key=api_key)

# -------------------------------------------------------
# 2. Tool í•¨ìˆ˜ ì •ì˜ (MCP ê¸°ëŠ¥, Mock API)
# -------------------------------------------------------

def get_heritage_text_record(location: str, structure_name: str) -> str:
    """
    íŠ¹ì • ì§€ì—­ê³¼ êµ¬ì¡°ë¬¼ì˜ ì´ë¦„ìœ¼ë¡œ ì—­ì‚¬ ê¸°ë¡ í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•˜ëŠ” Toolì…ë‹ˆë‹¤.
    (ì‹¤ì œë¡œëŠ” ê³µê³µë°ì´í„°í¬í„¸ APIë¥¼ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.)
    """
    time.sleep(1) # ì‹œë®¬ë ˆì´ì…˜ ì§€ì—°
    
    if "í™ê¸¸ë™" in structure_name:
        return json.dumps({
            "status": "success",
            "search_term": structure_name,
            "text_record": "í™ê¸¸ë™ ì‘ê°€ëŠ” 1920ë…„ëŒ€ ì´ˆ ì¼ë³¸ì—ì„œ ìœ í•™í–ˆìœ¼ë©°, ë‹¹ì‹œ íŒŒë¦¬ í™”ë‹¨ì˜ ì¶”ìƒì  ê²½í–¥ì— ì˜í–¥ì„ ë°›ì•˜ìœ¼ë‚˜, ê·€êµ­ í›„ ì¡°ì„ ë¯¸ìˆ ì „ëŒíšŒì—ì„œ 'ì¡°ì„ ì˜ í’ê²½'ì„ í…Œë§ˆë¡œ í•œ ì‹¤í—˜ì ì¸ ë‹¨ìƒ‰í™”(Monochrome)ë¥¼ ì£¼ë¡œ ì„ ë³´ì˜€ë‹¤. ì´ˆê¸°ì—ëŠ” ì±„ìƒ‰í™”ë„ ë³‘í–‰í–ˆìœ¼ë‚˜, í›„ê¸°ì—ëŠ” ìº”ë²„ìŠ¤ì— ë§ˆí¬ë¥¼ ì‚¬ìš©í•œ ë¬¼ì„± ìœ„ì£¼ ì‘ì—…ì— ì§‘ì¤‘í–ˆë‹¤.",
            "exhibition_count": 5
        })
    return json.dumps({"status": "error", "text_record": f"'{structure_name}'ì— ëŒ€í•œ ìƒì„¸ ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})

def generate_visualization_data(data: str, visualization_type: str) -> str:
    """
    ë¶„ì„ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œê°í™” ìë£Œ(JSON)ë¥¼ ìƒì„±í•˜ëŠ” Toolì…ë‹ˆë‹¤.
    (ì‹¤ì œë¡œëŠ” ë°ì´í„° í”„ë ˆì„ì„ ì²˜ë¦¬í•˜ê³  Plotly JSONì„ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.)
    """
    time.sleep(1.5) # ì‹œë®¬ë ˆì´ì…˜ ì§€ì—°
    
    if "ë‹¨ìƒ‰í™”" in data and visualization_type == "timeline":
        # LLMì´ ë¶„ì„í•œ ë‚´ìš©ì„ ì‹œê°í™” JSONìœ¼ë¡œ ë³€í™˜í–ˆë‹¤ê³  ê°€ì •
        return json.dumps({
            "status": "success",
            "visualization_type": "ì—°í‘œ",
            "data": [
                {"year": 1920, "event": "ì¼ë³¸ ìœ í•™ ë° ì„œì–‘ ì¶”ìƒí™” ê²½í–¥ ì ‘ì´‰"},
                {"year": 1925, "event": "ë‹¨ìƒ‰í™” ê¸°ë²• ì‹¤í—˜ ì‹œì‘"},
                {"year": 1930, "event": "ì¡°ì„ ë¯¸ìˆ ì „ëŒíšŒì—ì„œ ë§ˆí¬ ì§ˆê° ìœ„ì£¼ ì‘í’ˆ ë°œí‘œ"},
                {"year": 1935, "event": "ì´ˆê¸° ì±„ìƒ‰í™” í™œë™ ì¤‘ë‹¨"}
            ]
        })
    return json.dumps({"status": "error", "message": "ìš”ì²­ëœ ì‹œê°í™” ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})

# -------------------------------------------------------
# 3. Tool ìŠ¤í‚¤ë§ˆ ì •ì˜ ë° ë”•ì…”ë„ˆë¦¬
# -------------------------------------------------------

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_heritage_text_record",
            "description": "ì‘ê°€ë‚˜ ìœ ì‚°ì˜ ì´ë¦„ìœ¼ë¡œ ìƒì„¸í•œ ì—­ì‚¬ ê¸°ë¡ í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
            "parameters": {"type": "object", "properties": {"location": {"type": "string"}, "structure_name": {"type": "string"}}, "required": ["structure_name"]},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "generate_visualization_data",
            "description": "ì œê³µëœ ë¶„ì„ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—°í‘œ(timeline)ë‚˜ ì°¨íŠ¸(chart) í˜•íƒœì˜ ì‹œê°í™” JSON ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.",
            "parameters": {"type": "object", "properties": {"data": {"type": "string", "description": "ë¶„ì„í•  í…ìŠ¤íŠ¸ ê¸°ë¡ ì „ì²´"}, "visualization_type": {"type": "string", "description": "ì›í•˜ëŠ” ì‹œê°í™” í˜•ì‹ (ì—°í‘œ, ì°¨íŠ¸ ë“±)"}}, "required": ["data", "visualization_type"]},
        },
    },
]

available_functions = {
    "get_heritage_text_record": get_heritage_text_record,
    "generate_visualization_data": generate_visualization_data,
}


# -------------------------------------------------------
# 4. í•µì‹¬ ì—ì´ì „íŠ¸ ì‹¤í–‰ í•¨ìˆ˜ (MCP ë¡œì§)
# -------------------------------------------------------

def run_master_agent(user_prompt: str, location: str, structure_name: str, viz_type: str):
    
    client = get_openai_client() # í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
    messages = [{"role": "user", "content": user_prompt}]
    tool_results = {}
    
    st.info("AI ì—ì´ì „íŠ¸ê°€ ìš”ì²­ì„ ë¶„ì„í•˜ê³  Tool í˜¸ì¶œ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.")
    
    for i in range(3): # ìµœëŒ€ 3ë²ˆì˜ Tool í˜¸ì¶œ ê¸°íšŒ ë¶€ì—¬
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            tools=tools,
            tool_choice="auto",
        )
        
        response_message = response.choices[0].message
        
        # 1. ìµœì¢… í…ìŠ¤íŠ¸ ê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ ë£¨í”„ ì¢…ë£Œ
        if not response_message.tool_calls:
            return response_message.content, tool_results
        
        # 2. Tool Call ì‹¤í–‰
        messages.append(response_message)
        
        for tool_call in response_message.tool_calls:
            function_name = tool_call.function.name
            function_args = json.loads(tool_call.function.arguments)
            
            st.warning(f"STEP {i+1}: ğŸ› ï¸ ì—ì´ì „íŠ¸ê°€ Tool '{function_name}'ì„(ë¥¼) í˜¸ì¶œí•©ë‹ˆë‹¤.")
            
            # get_heritage_text_record í˜¸ì¶œ ì‹œ, UI ì…ë ¥ê°’ ì „ë‹¬
            if function_name == "get_heritage_text_record":
                function_args['location'] = location
                function_args['structure_name'] = structure_name
            
            # generate_visualization_data í˜¸ì¶œ ì‹œ, ì´ì „ ê²€ìƒ‰ ê²°ê³¼ì™€ ì‹œê°í™” íƒ€ì… ì „ë‹¬
            elif function_name == "generate_visualization_data":
                record = tool_results.get("get_heritage_text_record", {}).get("text_record", "")
                function_args['data'] = record
                function_args['visualization_type'] = viz_type
            
            function_response = available_functions[function_name](**function_args)
            
            # 3. Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê³  LLMì—ê²Œ ë‹¤ì‹œ ì „ë‹¬ (Chain of Thought)
            tool_results[function_name] = json.loads(function_response)
            messages.append({"tool_call_id": tool_call.id, "role": "tool", "content": function_response})
            
    # ìµœì¢… ì‘ë‹µ ì²˜ë¦¬ (ë£¨í”„ê°€ ëë‚˜ë„ ìµœì¢… ì‘ë‹µì´ ì—†ì„ ê²½ìš°)
    final_response = client.chat.completions.create(model="gpt-4o-mini", messages=messages)
    return final_response.choices[0].message.content, tool_results


# -------------------------------------------------------
# 5. Streamlit UI ë° ì‹¤í–‰ ë¡œì§
# -------------------------------------------------------

st.title("ğŸ“œ ì§€ì—­ ë¬¸í™”ìœ ì‚° ë””ì§€í„¸ ë§ˆìŠ¤í„° ì—ì´ì „íŠ¸")
st.markdown("ì—­ì‚¬ ê¸°ë¡ì„ ë¶„ì„í•˜ê³  ë©¸ì‹¤ëœ ìœ ì‚°ì˜ ë°°ê²½ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” (ì…ë ¥ ì˜ì—­)
with st.sidebar:
    st.header("ë¬¸í™”ìœ ì‚° ì •ë³´ ì…ë ¥")
    location = st.text_input("ì§€ì—­:", "ì„œìš¸ ì¢…ë¡œ")
    structure_name = st.text_input("ì‘ê°€/ìœ ì‚° ì´ë¦„:", "í™ê¸¸ë™ ì‘ê°€")
    
    viz_type = st.selectbox(
        "ë¶„ì„ ì‹œê°í™” í˜•ì‹:", 
        ['ì—°í‘œ', 'ì°¨íŠ¸', 'ì¼ë°˜ ë¶„ì„']
    )
    
    prompt = st.text_area(
        "AI ë¶„ì„ ìš”ì²­:", 
        f"'{structure_name}'ì˜ ì—­ì‚¬ ê¸°ë¡ì„ ê²€ìƒ‰í•˜ê³ , ê·¸ ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì£¼ìš” í™œë™ ì‹œê¸°ë¥¼ '{viz_type}' í˜•ì‹ìœ¼ë¡œ ì‹œê°í™”í•  ìˆ˜ ìˆë„ë¡ ë¶„ì„í•´ ì¤˜.",
        height=150
    )

# ë©”ì¸ ì‹¤í–‰ ë²„íŠ¼
if st.button("ğŸ” ë¶„ì„ ë° ì‹œê°í™” ì‹¤í–‰"): 
    if structure_name and prompt:
        with st.spinner("AI ì—ì´ì „íŠ¸ê°€ ê¸°ë¡ ê²€ìƒ‰ ë° ì‹œê°í™” ëª…ë ¹ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
            
            # 6. run_master_agent í•¨ìˆ˜ í˜¸ì¶œ
            analysis_text, tool_results = run_master_agent(prompt, location, structure_name, viz_type)
            
            # 7. ê²°ê³¼ ì¶œë ¥
            st.subheader("ğŸ’¡ ì—ì´ì „íŠ¸ ìµœì¢… ë¶„ì„ ë° ìŠ¤í† ë¦¬í…”ë§")
            st.write(analysis_text)
            
            if "get_heritage_text_record" in tool_results:
                record = tool_results["get_heritage_text_record"]
                if record.get("status") == "success":
                    st.subheader("ğŸ“œ ê²€ìƒ‰ëœ ì›ë³¸ ì—­ì‚¬ ê¸°ë¡")
                    st.code(record["text_record"], language='markdown')
            
            if "generate_visualization_data" in tool_results:
                viz_data = tool_results["generate_visualization_data"]
                if viz_data.get("status") == "success" and viz_data.get("visualization_type") == "ì—°í‘œ":
                    st.subheader("ğŸ“Š í™œë™ ì—°í‘œ ì‹œê°í™” ê²°ê³¼")
                    
                    # Mock ì—°í‘œ ë°ì´í„° Streamlit í…Œì´ë¸”ë¡œ ì¶œë ¥
                    df = st.dataframe(viz_data["data"], use_container_width=True)
                    st.markdown("_(ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” Plotly/Altairë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸í„°ë™í‹°ë¸Œí•œ ê·¸ë˜í”„ë¥¼ ì—¬ê¸°ì— í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)_")

    else:
        st.warning("ì‘ê°€/ìœ ì‚° ì´ë¦„ê³¼ ë¶„ì„ ìš”ì²­ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
